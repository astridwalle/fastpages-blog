{
  
    
        "post0": {
            "title": "Calculation of the R_eff numbers for Germany (overall and on regional level)",
            "content": "Code Toggling . from IPython.display import HTML import random def hide_toggle(for_next=False): this_cell = &quot;&quot;&quot;$(&#39;div.cell.code_cell.rendered.selected&#39;)&quot;&quot;&quot; next_cell = this_cell + &#39;.next()&#39; toggle_text = &#39;Toggle show/hide&#39; # text shown on toggle link target_cell = this_cell # target cell to control with toggle js_hide_current = &#39;&#39; # bit of JS to permanently hide code in current cell (only when toggling next cell) if for_next: target_cell = next_cell toggle_text += &#39; next cell&#39; js_hide_current = this_cell + &#39;.find(&quot;div.input&quot;).hide();&#39; js_f_name = &#39;code_toggle_{}&#39;.format(str(random.randint(1,2**64))) html = &quot;&quot;&quot; &lt;script&gt; function {f_name}() {{ {cell_selector}.find(&#39;div.input&#39;).toggle(); }} {js_hide_current} &lt;/script&gt; &lt;a href=&quot;javascript:{f_name}()&quot;&gt;{toggle_text}&lt;/a&gt; &quot;&quot;&quot;.format( f_name=js_f_name, cell_selector=target_cell, js_hide_current=js_hide_current, toggle_text=toggle_text ) return HTML(html) hide_toggle() . Toggle show/hide Imports . import pandas as pd import requests import datetime import numpy as np import matplotlib.pyplot as plt import seaborn as sns from scipy.stats import weibull_min from datetime import date import ipywidgets as widgets import difflib import random %matplotlib inline hide_toggle() . Toggle show/hide Data Import of RKI data . # raw unprocessed data df_rki=pd.read_csv(&quot;/project_data/data_asset/sun/casenumbers/rki_covid19.csv&quot;) # processed data: summed over all &quot;Landkreise&quot; and sorted according to &quot;Meldedatum&quot; df_rki_melde=pd.read_csv(&quot;/project_data/data_asset/mercury/casenumbers/RKI_ConfirmedCases_ReportingDate.csv&quot;) hide_toggle() . Toggle show/hide Proove whether data is up-to-date . print(df_rki[&quot;Datenstand&quot;].unique()) hide_toggle() . [&#39;18.06.2020, 00:00 Uhr&#39;] . Toggle show/hide Perform the logic check to get all new cases: . df_rki_temp = df_rki[((df_rki[&quot;NeuerFall&quot;]==0) | (df_rki[&quot;NeuerFall&quot;]==1))] hide_toggle() . Toggle show/hide Just for visualization purposes: Plot the case numbers for each &quot;Landkreis&quot; (regional levl in Germany) . # Plotting the casenumbers fig=plt.figure(figsize=(12,10)) ax1=fig.add_subplot(111) #ax.xaxis.set_major_formatter(daysFmt) df_rki_lk=df_rki_temp.groupby([&quot;Landkreis&quot;,&quot;Meldedatum&quot;],as_index=False)[[&quot;AnzahlFall&quot;]].sum() for i in df_rki_lk[&quot;Landkreis&quot;].unique(): df=df_rki_lk[df_rki_lk[&quot;Landkreis&quot;]==i] df.set_index(&quot;Meldedatum&quot;, inplace=True, drop=True) df.index=pd.to_datetime(df.index,format=&quot;%Y-%m-%d&quot;) df.sort_index(inplace=True) ax1.plot(df[&quot;AnzahlFall&quot;],color=&quot;grey&quot;,alpha=0.3) if &quot;Berlin&quot; in i: df_b=df df_rki_melde.index=pd.to_datetime(df_rki_melde.index,format=&quot;%Y-%m-%d&quot;) ax1.plot(df_rki_melde[&quot;AnzahlFall&quot;],color=&quot;blue&quot;,label=&quot;Germany&quot;) ax1.plot(df_b[&quot;AnzahlFall&quot;],color=&quot;red&quot;,label=&quot;Berlin&quot;) plt.yscale(&quot;log&quot;) plt.title(&quot;Casenumbers - Reporting Date - for each Landkreis in Germany&quot;) #plt.legend() hide_toggle() . Toggle show/hide Setting the sliding window size for the R_eff calculation (RKI uses 4 days). . This value is used for the summation of cases (e.g. sum of cases 2020-04-05 - 2020-04-08) as well as for the calculation of the ratio (e.g. sum(2020-05-06)/sum(2020-05-09)) . # set the timewindow for sliding window # RKI uses 4 days: window=widgets.IntSlider( value=4, min=0, max=10, step=1, description=&#39;Sliding time window&#39;, disabled=False, continuous_update=False, orientation=&#39;horizontal&#39;, readout=True, readout_format=&#39;d&#39; ) display(window) hide_toggle() . Toggle show/hide Routine for padding the timeseries . # Routine for padding the timeseries idx = pd.IndexSlice date_index=pd.date_range(start=&#39;01/01/2020&#39;,end=date.today(),freq=&#39;D&#39;) def filldates(df): df.reset_index(drop=True,inplace=True) df=df.asfreq(&quot;1D&quot;,fill_value=0.0).reindex(date_index,fill_value=0.0) return df hide_toggle() . Toggle show/hide Routine to create a linelist from the RKI data . # Routine to create a linelist from the RKI data def create_linelist(df_rki): HELP1=[] HELP2=[] for index,row in df_rki.iterrows(): i=1 while i&lt;=row[&quot;AnzahlFall&quot;]: HELP1.append(row[&quot;Meldedatum&quot;]) HELP2.append(row[&quot;Refdatum&quot;]) i+=1 HELP1=pd.to_datetime(HELP1) HELP2=pd.to_datetime(HELP2) df_linelist=pd.DataFrame(columns=[&quot;Meldedatum&quot;,&quot;Erkrankungsdatum&quot;],data=list(zip(HELP1,HELP2))) # list with only valid dates, delay &gt; 0 days df_linelist_clean=df_linelist[df_linelist[&quot;Meldedatum&quot;]&gt;df_linelist[&quot;Erkrankungsdatum&quot;]] # Include the delay of 0 days for cases where we do not have the symptoms onset date. df_linelist.loc[:,&quot;delay&quot;]=df_linelist[&quot;Meldedatum&quot;]-df_linelist[&quot;Erkrankungsdatum&quot;] # to use for cw as a covariate! df_linelist.loc[:,&quot;cw&quot;]=[i.isocalendar()[1] for i in df_linelist[&quot;Meldedatum&quot;]] # just for the cases where we do have both dates df_linelist_clean.loc[:,&quot;delay&quot;]=df_linelist_clean[&quot;Meldedatum&quot;]-df_linelist_clean[&quot;Erkrankungsdatum&quot;] # to use for cw as a covariate! df_linelist_clean.loc[:,&quot;cw&quot;]=[i.isocalendar()[1] for i in df_linelist_clean[&quot;Meldedatum&quot;]] return df_linelist, df_linelist_clean hide_toggle() . Toggle show/hide Routine for performing the imputation - Fitting Weibull Distribution for reporting delay, according to: https://www.medrxiv.org/content/10.1101/2020.03.18.20037473v1 . # Routine for performing the imputation # Fitting Weibull Distribution def imputation(df_linelist,df_linelist_clean): shape, loc, scale = weibull_min.fit(df_linelist_clean[&quot;delay&quot;].dt.days, floc=0) wb_row=[name,shape,loc,scale] # distribute missing values accordingly to that distribution: # create random numbers and assign to the missing delay values in the dataframe: # overall values size=len(df_linelist) r=weibull_min.rvs(shape,loc=loc,scale=scale,size=size) df_linelist.loc[:,&quot;delay_weibull&quot;]=[datetime.timedelta(days=int(i)) for i in r] df_linelist.loc[:,&quot;Erkrankungsdatum Weibull&quot;]=df_linelist[&quot;Meldedatum&quot;]-df_linelist[&quot;delay_weibull&quot;] #print(np.mean(df_linelist[&quot;delay_weibull&quot;])) # combine the known values with the imputated values: df_linelist.loc[df_linelist[&quot;delay&quot;].dt.days&lt;=0,&quot;Combined&quot;]=df_linelist.loc[df_linelist[&quot;delay&quot;].dt.days&lt;=0,&quot;Erkrankungsdatum Weibull&quot;] df_linelist.loc[df_linelist[&quot;delay&quot;].dt.days&gt;0,&quot;Combined&quot;]=df_linelist.loc[df_linelist[&quot;delay&quot;].dt.days&gt;0,&quot;Erkrankungsdatum&quot;] onset_combined=df_linelist[&quot;Combined&quot;].value_counts() # padding the timeseries data to get an entry for every day onset_combined.sort_index(inplace=True) onset_combined=onset_combined.asfreq(&quot;1D&quot;,fill_value=0.0).reindex(date_index,fill_value=0.0) number=max(df_linelist[&quot;delay&quot;].dt.days) # calculate p_delay for nowcasting routine p_delay=pd.Series(data=weibull_min.pdf(np.arange(0,number),shape,loc=loc,scale=scale),index=np.arange(0,number)) return onset_combined,p_delay,wb_row hide_toggle() . Toggle show/hide Nowcasting routine - taken from rt.live (https://github.com/k-sys/covid-19/blob/master/Realtime%20Rt%20mcmc.ipynb) . # Nowcasting Routine from rt.live def adjust_onset_for_right_censorship(onset, p_delay): cumulative_p_delay = p_delay.cumsum() # Calculate the additional ones needed so shapes match ones_needed = len(onset) - len(cumulative_p_delay) padding_shape = (0, ones_needed) # Add ones and flip back cumulative_p_delay = np.pad( cumulative_p_delay, padding_shape, mode=&quot;constant&quot;, constant_values=1) cumulative_p_delay = np.flip(cumulative_p_delay) # Adjusts observed onset values to expected terminal onset values adjusted = onset / cumulative_p_delay return adjusted, cumulative_p_delay hide_toggle() . Toggle show/hide ?np.pad . Routine for performing the r_eff calculation . # Routine for performing the r_eff calculation def calculate_reff(onset_adjusted): df_rolling=onset_adjusted.rolling(window.value).sum() r_t=df_rolling.pct_change(periods=window.value)+1.0 r_t.sort_index(inplace=True) return r_t hide_toggle() . Toggle show/hide Multicheckbox from github --&gt; https://gist.github.com/pbugnion/5bb7878ff212a0116f0f1fbc9f431a5c . # multicheckbox from github def multi_checkbox_widget(descriptions): &quot;&quot;&quot; Widget with a search field and lots of checkboxes &quot;&quot;&quot; search_widget = widgets.Text() options_dict = {description: widgets.Checkbox(description=description, value=False) for description in descriptions} options = [options_dict[description] for description in descriptions] options_widget = widgets.VBox(options, layout={&#39;overflow&#39;: &#39;scroll&#39;}) multi_select = widgets.VBox([search_widget, options_widget]) # Wire the search field to the checkboxes def on_text_change(change): search_input = change[&#39;new&#39;] if search_input == &#39;&#39;: # Reset search field new_options = [options_dict[description] for description in descriptions] else: # Filter by search field using difflib. close_matches = difflib.get_close_matches(search_input, descriptions, cutoff=0.0) new_options = [options_dict[description] for description in close_matches] options_widget.children = new_options search_widget.observe(on_text_change, names=&#39;value&#39;) return multi_select hide_toggle() . Toggle show/hide Now the calculation procedure is performed for each Landkreis and the results (numbers and weibull coefficients) are stored in df&#39;s . create linelist | imputation | nowcasting | r_eff calculation | . # do the complete calculation for all Landkreise: data=[] imputed=pd.DataFrame(index=date_index) nowcast=pd.DataFrame(index=date_index) r_eff=pd.DataFrame(index=date_index) grouped=df_rki_temp.groupby(&quot;Landkreis&quot;) for name, df in grouped: # create linelist df_linelist, df_linelist_clean = create_linelist(df) # perform imputation onset_combined,p_delay,wb_row = imputation(df_linelist,df_linelist_clean) # perform nowcasting onset_adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset_combined, p_delay) # calculate r_t r_t=calculate_reff(onset_adjusted) # add the Series data to the DataFrames imputed[name]=onset_combined nowcast[name]=onset_adjusted r_eff[name]=r_t data.append(wb_row) # save the curve parameters to a dataframe df_wb=pd.DataFrame(columns=[&quot;LK&quot;,&quot;shape&quot;,&quot;loc&quot;,&quot;scale&quot;],data=data) df_wb=df_wb.set_index(&quot;LK&quot;) hide_toggle() . /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.obj[key] = _infer_fill_value(value) /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.obj[item] = s /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py:1821: RuntimeWarning: divide by zero encountered in power return c*pow(x, c-1)*np.exp(-pow(x, c)) . Toggle show/hide Do the calculation for all LK&#39;s in Berlin to get an overall result for Berlin . # do the calculation for Berlin: lk=[i for i in df_rki_temp[&quot;Landkreis&quot;].unique() if &quot;Berlin&quot; in i] df=df_rki_temp[df_rki_temp[&quot;Landkreis&quot;].isin(lk)] # create linelist df_linelist, df_linelist_clean = create_linelist(df) # perform imputation onset_combined,p_delay,wb_row = imputation(df_linelist,df_linelist_clean) # perform nowcasting onset_adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset_combined, p_delay) # calculate r_t r_t=calculate_reff(onset_adjusted) # add the Series data to the DataFrames imputed[&quot;Berlin&quot;]=onset_combined nowcast[&quot;Berlin&quot;]=onset_adjusted r_eff[&quot;Berlin&quot;]=r_t hide_toggle() . /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.obj[key] = _infer_fill_value(value) /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.obj[item] = s . Toggle show/hide Do the calculation for all LK&#39;s to get an overall result for Germany . # do the calculation for overall Germany: # create linelist df_linelist, df_linelist_clean = create_linelist(df_rki_temp) # perform imputation # this can also be done with calendar week as a covariate! onset_combined,p_delay,wb_row = imputation(df_linelist,df_linelist_clean) # perform nowcasting onset_adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset_combined, p_delay) # calculate r_t r_t=calculate_reff(onset_adjusted) # add the Series data to the DataFrames imputed[&quot;Germany&quot;]=onset_combined nowcast[&quot;Germany&quot;]=onset_adjusted r_eff[&quot;Germany&quot;]=r_t hide_toggle() . /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.obj[key] = _infer_fill_value(value) /opt/conda/envs/Python-3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.obj[item] = s . Toggle show/hide Multiple selection Checkbox for selection of multiple LK&#39;s for plotting the r_eff values . select_plot = multi_checkbox_widget(nowcast.columns.values) hide_toggle() . Toggle show/hide select_plot # Display the widget . Plot r_eff for the selected LK&#39;s . fig, ax = plt.subplots(figsize=(10,6)) for name in [w.description for w in select_plot.children[1].children if w.value]: print(name) ax.plot(r_eff.index,r_eff[name],label=name) ax.hlines(y=1.0,xmin=min(r_eff.index),xmax=max(r_eff.index),lw=1.0) plt.ylim([0,4]) plt.legend() plt.title(&quot;Reproduction number for selected Landkreise&quot;) hide_toggle() . Germany Berlin . Toggle show/hide Evaluation / Validation / Visualization for Germany and Comparison with official published numbers . Import of published numbers (as of 2020-06-18) &lt;https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Projekte_RKI/Nowcasting_Zahlen.html&gt; . # Vergleich mit nowcasting werten des RKI df=pd.read_excel(&quot;/project_data/data_asset/Nowcasting_Zahlen_20200618.xlsx&quot;,sheet_name=&quot;Nowcast_R&quot;) hide_toggle() . Toggle show/hide Visualization / Exploration for Germany&#39;s reporting delay . # Visualization / Exploration for Germany print(&quot;cases with given symptoms onset date: &quot;,len(df_linelist_clean)) print(&quot;cases with missing symptoms onset date: &quot;,len(df_linelist)-len(df_linelist_clean), (len(df_linelist)-len(df_linelist_clean))/len(df_linelist)*100,&quot;%&quot;) plt.figure(figsize=(10,6)) plt.hist(df_linelist_clean[&quot;delay&quot;].dt.days, density=True, alpha=0.5,bins=50,color=&quot;blue&quot;) x = np.linspace(df_linelist_clean[&quot;delay&quot;].dt.days.min(), df_linelist_clean[&quot;delay&quot;].dt.days.max(), 100) plt.plot(x, weibull_min(wb_row[1], wb_row[2], wb_row[3]).pdf(x),color=&quot;black&quot;) plt.title(&quot;Histogram and fitted Weibull distribution for the reporting delay&quot;) print(&quot;delay mean:&quot;,np.mean(df_linelist_clean[&quot;delay&quot;].dt.days)) print(&quot;delay median:&quot;,np.median(df_linelist_clean[&quot;delay&quot;].dt.days)) print(&quot;delay std&quot;,np.std(df_linelist_clean[&quot;delay&quot;].dt.days)) print(&quot;could be a lot of different curves for cw&#39;s&quot;) hide_toggle() . cases with given symptoms onset date: 127723 cases with missing symptoms onset date: 60041 31.97684327134062 % delay mean: 6.884468733117763 delay median: 6.0 delay std 5.768248051384243 could be a lot of different curves for cw&#39;s . Toggle show/hide Now we do a plot to compare the reported cases with symptoms onset date with our imputed datasets . using only the imputed dates (applying the weibull delay distribution to all datapoints) | using a combination of reported cases and imputed datapoints, only when there was no symptons onset date given | . # plot the reported cases with onset symptoms date and the imputed # compare with the nowcasted values from RKI: onset_imputed=df_linelist[&quot;Erkrankungsdatum Weibull&quot;].value_counts() onset_real=df_linelist_clean[&quot;Erkrankungsdatum&quot;].value_counts() #onset_imputed_rki=df_rki_cw[&quot;Erkrankungsdatum Weibull&quot;].value_counts() onset_imputed.sort_index(inplace=True) onset_real.sort_index(inplace=True) fig, ax = plt.subplots(figsize=(10,6)) plt.plot(onset_real, color=&quot;black&quot;, label=&quot;given symptoms onset date&quot;) plt.plot(onset_imputed,&quot;g-.&quot;, label=&quot;only imputed symptoms onset date&quot;) plt.plot(onset_combined,color=&quot;red&quot;,label=&quot;combined imputed/given symptoms onset date&quot;) plt.legend() plt.title(&quot;Comparison: Imputation applied to all datapoints / mising datapoints&quot;) hide_toggle() . Toggle show/hide We can see that it is no good fit when the imputation is applied to all datapoints, so we rather go with the combined dataset! . In the next plot we compare our nowcasted values (based on the combined imputed timeseries) with the nowcast values from RKI . fig, ax = plt.subplots(figsize=(10,6)) plt.plot(onset_real, color=&quot;black&quot;, label=&quot;given symptoms onset date&quot;) plt.plot(onset_combined,color=&quot;red&quot;,label=&quot;combined imputed/given symptoms onset date&quot;) plt.plot(onset_adjusted,&quot;g-.&quot;, label=&quot;nowcasted symptoms onset date&quot;) plt.plot(df[&quot;Datum des Erkrankungsbeginns&quot;],df[&quot;Punktschätzer der Anzahl Neuerkrankungen&quot;],&quot;g:&quot;,label=&quot;nowcasted values from RKI&quot;) plt.legend() plt.title(&quot;Comparison of Nowcasted Values&quot;) hide_toggle() . Toggle show/hide We can see a good fit between our values and the RKI values, so the applied methods seem to be correct. . Open questions are still: . For how many cases does one need the symptoms onset date given to get a &quot;valid&quot; distribution. | . In the next plot we take a look at the calculated r_eff and the RKI r_eff values . fig, ax = plt.subplots(figsize=(10,6)) plt.plot(r_t,&quot;k--&quot;,label=&quot;r_eff&quot;) ax.plot(df[&quot;Datum des Erkrankungsbeginns&quot;],df[&quot;Punktschätzer der Reproduktionszahl R&quot;], label=&quot;r_eff RKI&quot;) ax.hlines(y=1.0,xmin=min(r_eff.index),xmax=max(r_eff.index),lw=1.0) plt.ylim([0,4]) plt.legend() plt.title(&quot;Comparison of r_eff&quot;) hide_toggle() . Toggle show/hide Possible Extension: Perform the Weibull fitting with the calendar week as a covariate. . This takes into account, that the reporting routines and procedures do change during the pandemic . We rerun the part for overall Germany, and just using another routine for the fitting the Weibull distribution. . In the created linelists we already introduced another column for the calendarweek, of which we can make use now. . Then we plot all Weibull curves for all calendar weeks to the deviation. . # do the calculation for overall Germany - with calendar week as covariate: # create linelist df_linelist, df_linelist_clean = create_linelist(df_rki_temp) # fit Weibull distributions for every calendar week data=[] grouped=df_linelist_clean.groupby(&quot;cw&quot;) for name,group in grouped: shape, loc, scale = weibull_min.fit(group[&quot;delay&quot;].dt.days, floc=0) row=[name,shape,loc,scale] data.append(row) # dataframe with Weibull coefficients for every calendar week df_wb=pd.DataFrame(columns=[&quot;cw&quot;,&quot;shape&quot;,&quot;loc&quot;,&quot;scale&quot;],data=data) df_wb=df_wb.set_index(&quot;cw&quot;) # just for comparison: Weibull shape parameters for overall data (redoing the former calculation) shape_ges, loc_ges, scale_ges = weibull_min.fit(df_linelist_clean[&quot;delay&quot;].dt.days, floc=0) # plot the curves x = np.linspace(df_linelist_clean[&quot;delay&quot;].dt.days.min(), df_linelist_clean[&quot;delay&quot;].dt.days.max(), 100) fig, ax = plt.subplots(figsize=(10,6)) for row in df_wb.iterrows(): ax.plot(x, weibull_min(row[1][0], row[1][1],row[1][2]).pdf(x),label=row[0]) ax.plot(x, weibull_min(shape_ges, loc_ges, scale_ges).pdf(x),color=&quot;black&quot;) plt.legend() plt.title(&quot;Comparison of Fitted Weibull Curves for the reporting delay for each calendar week&quot;) hide_toggle() . Toggle show/hide Save the dataframes for imputed / nowcasted and r_eff numbers for all Landkreise in Germany . import pickle def save_obj(obj, name): with open(&#39;/project_data/data_asset/venus/r_eff_numbers_germany/&#39;+ name + &#39;.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL) def load_obj(name ): with open(&#39;/project_data/data_asset/venus/r_eff_numbers_germany/&#39; + name + &#39;.pkl&#39;, &#39;rb&#39;) as f: return pickle.load(f) hide_toggle() . Toggle show/hide save_obj(imputed,&quot;imputed&quot;) #imputed=load_obj(&quot;imputed&quot;) . save_obj(nowcast,&quot;nowcast&quot;) #nowcast=load_obj(&quot;nowcast&quot;) . save_obj(r_eff,&quot;r_eff&quot;) #r_eff=load_obj(&quot;r_eff&quot;) .",
            "url": "https://astridwalle.github.io/fastpages-blog/2020/06/19/WS1-aw-r-eff-germany.html",
            "relUrl": "/2020/06/19/WS1-aw-r-eff-germany.html",
            "date": " • Jun 19, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://astridwalle.github.io/fastpages-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://astridwalle.github.io/fastpages-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://astridwalle.github.io/fastpages-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://astridwalle.github.io/fastpages-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}